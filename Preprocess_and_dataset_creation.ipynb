{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64e5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_process as pp\n",
    "import utils as u\n",
    "import dataset as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib as jb\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee19adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_tr = u.get_path_list(\"D:/isip.piconepress.com/projects/nedc/data/tuh_eeg/tuh_eeg_abnormal/v3.0.1/edf/train\",['.edf'],True)\n",
    "path_list_eval = u.get_path_list(\"D:/isip.piconepress.com/projects/nedc/data/tuh_eeg/tuh_eeg_abnormal/v3.0.1/edf/eval\",['.edf'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9d26d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2717,)\n",
      "<class 'numpy.ndarray'>\n",
      "(276,)\n"
     ]
    }
   ],
   "source": [
    "print(type(path_list_tr))\n",
    "print(path_list_tr.shape)\n",
    "print(type(path_list_eval))\n",
    "print(path_list_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d9e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id_list_tr= [f\"campione_{i}_tr\" for i in range(1, 2718)]\n",
    "path_id_list_eval= [f\"campione_{i}_eval\" for i in range(1, 277)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84497f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_tr = pd.DataFrame({'Path_id':path_id_list_tr, 'Path':path_list_tr})\n",
    "df_path_eval = pd.DataFrame({'Path_id':path_id_list_eval, 'Path':path_list_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31d7f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path_id</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>campione_2713_tr</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>campione_2714_tr</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>campione_2715_tr</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>campione_2716_tr</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>campione_2717_tr</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Path_id                                               Path\n",
       "2712  campione_2713_tr  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "2713  campione_2714_tr  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "2714  campione_2715_tr  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "2715  campione_2716_tr  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "2716  campione_2717_tr  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path_tr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0171f19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path_id</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>campione_272_eval</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>campione_273_eval</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>campione_274_eval</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>campione_275_eval</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>campione_276_eval</td>\n",
       "      <td>D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Path_id                                               Path\n",
       "271  campione_272_eval  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "272  campione_273_eval  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "273  campione_274_eval  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "274  campione_275_eval  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh...\n",
       "275  campione_276_eval  D:\\isip.piconepress.com\\projects\\nedc\\data\\tuh..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path_eval.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3710b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_tr.to_csv('path_tr.csv', index=False, encoding='utf-8-sig')\n",
    "df_path_eval.to_csv('path_eval.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852d6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(in_file, out_dir, out_prefix):\n",
    "    try:\n",
    "        dg = pp.data_gen(in_file, out_dir, out_prefix)\n",
    "        dg.save_final_data(seg_len=5.0, merge_len=1)\n",
    "    except:\n",
    "        flag = False\n",
    "        time.sleep(3.0)\n",
    "    else:\n",
    "        flag = True\n",
    "    return in_file, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4109fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_file_tr = \"path_tr.csv\"\n",
    "out_dir_tr = \"D:/raw_data_tr\"\n",
    "log_file_tr = \"D:/raw_data_tr/log_tr.csv\"\n",
    "md_file_eval = \"path_eval.csv\"\n",
    "out_dir_eval = \"D:/raw_data_eval\"\n",
    "log_file_eval = \"D:/raw_data_eval/log_tr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6042c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\isip.piconepress.com\\\\projects\\\\nedc\\\\data\\\\tuh_eeg\\\\tuh_eeg_abnormal\\\\v3.0.1\\\\edf\\\\train\\\\abnormal\\\\01_tcp_ar\\\\aaaaaaaq_s004_t000.edf',\n",
       " 'campione_1_tr')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(out_dir_tr):\n",
    "    os.makedirs(out_dir_tr)\n",
    "\n",
    "df_path_tr = pd.read_csv(md_file_tr)\n",
    "tasks_tr = [(Pt, Pt_id) for Pt, Pt_id in zip(df_path_tr.Path, df_path_tr.Path_id)]\n",
    "tasks_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b98682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\isip.piconepress.com\\\\projects\\\\nedc\\\\data\\\\tuh_eeg\\\\tuh_eeg_abnormal\\\\v3.0.1\\\\edf\\\\eval\\\\abnormal\\\\01_tcp_ar\\\\aaaaabdo_s003_t000.edf',\n",
       " 'campione_1_eval')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(out_dir_eval):\n",
    "    os.makedirs(out_dir_eval)\n",
    "\n",
    "df_path_eval = pd.read_csv(md_file_eval)\n",
    "tasks_eval = [(Pt, Pt_id) for Pt, Pt_id in zip(df_path_eval.Path, df_path_eval.Path_id)]\n",
    "tasks_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a0b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [09:00<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "n_jobs = jb.cpu_count()\n",
    "res = jb.Parallel(n_jobs=n_jobs, backend='loky')(jb.delayed(worker)(in_file, out_dir_eval, out_f_id) for in_file, out_f_id in tqdm(tasks_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df802acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.DataFrame(res, columns=['path', 'status'])\n",
    "df_log.to_csv(log_file_eval, index=False, encoding=\"utf-8-sig\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dd7125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2717/2717 [1:17:02<00:00,  1.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m n_jobs = jb.cpu_count()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43mjb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloky\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_f_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_f_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks_tr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pitom\\OneDrive\\Desktop\\materiale uni\\Tesi\\TESI-TRIENNALE\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pitom\\OneDrive\\Desktop\\materiale uni\\Tesi\\TESI-TRIENNALE\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pitom\\OneDrive\\Desktop\\materiale uni\\Tesi\\TESI-TRIENNALE\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_jobs = jb.cpu_count()\n",
    "res = jb.Parallel(n_jobs=n_jobs, backend='loky')(jb.delayed(worker)(in_file, out_dir_tr, out_f_id) for in_file, out_f_id in tqdm(tasks_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.DataFrame(res, columns=['path', 'status'])\n",
    "df_log.to_csv(log_file_tr, index=False, encoding=\"utf-8-sig\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd264b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_tr = u.get_path_list('D:/raw_data_tr', ['.npy'], True)\n",
    "path_list_eval = u.get_path_list('D:/raw_data_eval', ['.npy'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273cc737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2713/2713 [16:30<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clips:  Counter({500: 2713})\n",
      "number of channels:  Counter({6: 2713})\n",
      "different frequencies:  Counter({1250: 2713})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [01:44<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clips:  Counter({500: 276})\n",
      "number of channels:  Counter({6: 276})\n",
      "different frequencies:  Counter({1250: 276})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clips = []\n",
    "chans = []\n",
    "freqs = []\n",
    "for path in tqdm(path_list_tr):\n",
    "    file = np.load(path)\n",
    "    clips.append(file.shape[0])\n",
    "    chans.append(file.shape[1])\n",
    "    freqs.append(file.shape[2])\n",
    "print(\"number of clips: \", Counter(clips))\n",
    "print(\"number of channels: \", Counter(chans))\n",
    "print(\"different frequencies: \", Counter(freqs))\n",
    "clips = []\n",
    "chans = []\n",
    "freqs = []\n",
    "for path in tqdm(path_list_eval):\n",
    "    file = np.load(path)\n",
    "    clips.append(file.shape[0])\n",
    "    chans.append(file.shape[1])\n",
    "    freqs.append(file.shape[2])\n",
    "print(\"number of clips: \", Counter(clips))\n",
    "print(\"number of channels: \", Counter(chans))\n",
    "print(\"different frequencies: \", Counter(freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896b5437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths presi\n",
      "create liste di train e test dei path\n",
      "create directory di test e train\n",
      "inizio salvataggio file di train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2713/2713 [15:15<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6, 250)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.58 GiB for an array with shape (1356500, 6, 250) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m files_directory_tr = \u001b[33m\"\u001b[39m\u001b[33mD:/raw_data_tr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m out_directory_tr = \u001b[33m\"\u001b[39m\u001b[33mD:/Dataset_tr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_save_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles_directory_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_directory_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pitom\\OneDrive\\Desktop\\materiale uni\\Tesi\\TESI-TRIENNALE\\dataset.py:92\u001b[39m, in \u001b[36mmake_save_dataset\u001b[39m\u001b[34m(f_dir, out_dir, ratio, seed, clip_len)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ratio != \u001b[32m1.0\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minizio salvataggio file di train\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43mmerge_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtr_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDONE!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pitom\\OneDrive\\Desktop\\materiale uni\\Tesi\\TESI-TRIENNALE\\dataset.py:38\u001b[39m, in \u001b[36mmerge_data\u001b[39m\u001b[34m(path_list, out_dir, seed, clip_len)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(data_cut[\u001b[32m0\u001b[39m].shape)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m#concateno lungo la dimensione del numero dei campioni ottenendo [n_campioni totale, 6, lunghezza campione]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m data_cut = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m np.random.shuffle(data_cut)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m#salvo 6 file (1 per banda) con la forma [n_campioni totali, lunghezza campione]\u001b[39;00m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 7.58 GiB for an array with shape (1356500, 6, 250) and data type float32"
     ]
    }
   ],
   "source": [
    "files_directory_tr = \"D:/raw_data_tr\"\n",
    "out_directory_tr = \"D:/Dataset_tr\"\n",
    "dt.make_save_dataset(f_dir=files_directory_tr, out_dir=out_directory_tr, ratio=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48013b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths presi\n",
      "create liste di train e test dei path\n",
      "create directory di test e train\n",
      "inizio salvataggio file di test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [01:28<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6, 250)\n",
      "save whole to D:/Dataset_eval\\test\n",
      "save delta to D:/Dataset_eval\\test\n",
      "save theta to D:/Dataset_eval\\test\n",
      "save alpha to D:/Dataset_eval\\test\n",
      "save low_beta to D:/Dataset_eval\\test\n",
      "save high_beta to D:/Dataset_eval\\test\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "files_directory_eval = \"D:/raw_data_eval\"\n",
    "out_directory_eval = \"D:/Dataset_eval\"\n",
    "dt.make_save_dataset(f_dir=files_directory_eval, out_dir=out_directory_eval, ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da16aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  D:/Training_dataset/train\\whole.npy\n",
      "elementi: 1196000\n",
      "lunghezza campione: 250\n",
      "lunghezza voluta clip: 250\n"
     ]
    }
   ],
   "source": [
    "from dataset import ClipDS\n",
    "import torch\n",
    "train_ds = ClipDS(data_dir='D:/Training_dataset/train',\n",
    "                  band_name='whole',\n",
    "                  clip_len=250)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=16, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a3e0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 250])\n",
      "<class 'torch.Tensor'>\n",
      "(16, 1, 250)\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 1, 250)\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i.shape)\n",
    "    print(type(i))\n",
    "    i = i.numpy()\n",
    "    print(i.shape)\n",
    "    print(type(i))\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745baaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
